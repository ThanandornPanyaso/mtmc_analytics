{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6629686",
   "metadata": {},
   "source": [
    "## Visualization Notebook for RTLS Results\n",
    "\n",
    "<img src=\"images/viz_rtls_sample.png\" width=1080/>\n",
    "\n",
    "### This notebook generates a bird's-eye view (BEV) video for the visualization of outputs from the RTLS (Real-Time Location System) reference application.\n",
    "\n",
    "Central to the video is the floor plan map, serving as the primary display area, onto which moving tracklets for each detected global ID are superimposed. Users have the option to incorporate camera views around the perimeter of the floor plan. When these views are activated, the video integrates the detection and tracking results from individual cameras. Furthermore, if camera views are enabled, the video sequence includes a rotation through each camera, sequentially spotlighting its view. This process involves highlighting the selected camera's perspective and projecting its field of view (FOV) onto the floor plan map, ensuring each camera is featured individually at the start of the video.\n",
    "\n",
    "#### Configuration\n",
    "\n",
    "A configuration file in JSON format needs to be provided for this notebook to work. A sample configuration file is given as follows:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"inputSetting\": {\n",
    "        \"calibrationPath\": \"path/to/calibration.json\",\n",
    "        \"mapPath\": \"path/to/map.png\",\n",
    "        \"rtlsLogPath\": \"path/to/mdx-rtls.log\",\n",
    "        \"videoDirPath\": \"path/to/folder/containing/videos\",\n",
    "        \"rawDataPath\": \"path/to/raw_data.log\"\n",
    "    },\n",
    "    \"outputSetting\": {\n",
    "        \"outputVideoPath\": \"path/to/output_video.mp4\",\n",
    "        \"outputMapHeight\": 1080,\n",
    "        \"displaySensorViews\": false,\n",
    "        \"sensorViewsLayout\": \"radial\",\n",
    "        \"sensorViewDisplayMode\": \"rotational\",\n",
    "        \"sensorFovDisplayMode\": \"rotational\",\n",
    "        \"skippedBeginningTimeSec\": 0.0,\n",
    "        \"outputVideoDurationSec\": 60.0,\n",
    "        \"sensorSetup\": 8,\n",
    "        \"bufferLengthThreshSec\": 3.0,\n",
    "        \"trajectoryLengthThreshSec\": 5.0,\n",
    "        \"sensorViewStartTimeSec\": 2.0,\n",
    "        \"sensorViewDurationSec\": 1.0,\n",
    "        \"sensorViewGapSec\": 0.1\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "- **`calibrationPath`**: Path to the standard Metropolis calibration file.\n",
    "- **`mapPath`**: Path to the floor plan map image, utilized for plotting in BEV.\n",
    "- **`rtlsLogPath`**: Path to the log file containing Kafka messages from the `mdx-rtls` topic, which includes the RTLS results in JSON format.\n",
    "- **`videoDirPath`**: Directory path containing videos from each camera. This parameter is disregarded if `displaySensorViews` is `false`.\n",
    "- **`rawDataPath`**: Path to the raw data that contains DeepStream perception results in JSON or protobuf format. In this example, the protobuf format with potential AMR data is used. This parameter is ignored if `displaySensorViews` is `false`.\n",
    "- **`outputVideoPath`**: Path where the output video file will be saved.\n",
    "- **`outputMapHeight`**: The height of the map image in the output video.\n",
    "- **`displaySensorViews`**: A boolean flag to enable or disable the display of camera views. Enabling this can significantly increase RAM usage and slow down processing, depending on the number of cameras involved.\n",
    "- **`sensorViewsLayout`**: The sensor views' layout has two options - \"radial\" and \"split\". The radial layout shows sensor views surrounding the map view at the center. The split layout shows the sensor views on the left and the map view on the right. This parameter is required if `displaySensorViews` is `true`.\n",
    "- **`sensorViewDisplayMode`**: The display mode of the sensor views has two options - \"rotational\" and \"cumulative\". The rotational mode highlights each sensor view individually in a rotational manner. The cumulative mode keeps all the previous sensor views highlighted while circling through all sensor views. This parameter is required if `displaySensorViews` is `true`.\n",
    "- **`sensorFovDisplayMode`**: The display mode of sensors' FOV in the map of floor plan has two options - \"rotational\" and \"cumulative\". The rotational mode displays each sensor's FOV individually in a rotational manner. The cumulative mode keeps all the previous sensors' FOV displayed while circling through all sensors. This parameter is required if `displaySensorViews` is `true`.\n",
    "- **`skippedBeginningTimeSec`**: Duration (in seconds) to skip at the beginning of the output video, accommodating for RTLS initialization time.\n",
    "- **`outputVideoDurationSec`**: Specifies the length of the output video. Adjusting this value helps manage the balance between quick checks and generating longer video outputs.\n",
    "- **`sensorSetup`**: Required only if `displaySensorViews` is `true`. Specifies the configuration for tiled windows based on the number of cameras. Supported configurations are for 8, 12, 16, 30, 40, and 100 cameras. Selecting a configuration with fewer cameras than you have will display only that number, and choosing a larger configuration will leave additional windows blank.\n",
    "- **`bufferLengthThreshSec`**: Threshold for buffered locations in seconds, used for smoothing trajectories.\n",
    "- **`trajectoryLengthThreshSec`**: Maximum trajectory length threshold in seconds for plotting on the floor plan.\n",
    "- **`sensorViewStartTimeSec`**: Start time for displaying each camera view in the rotation, required if `displaySensorViews` is `true`.\n",
    "- **`sensorViewDurationSec`**: Duration for displaying each camera view in the rotation, required if `displaySensorViews` is `true`.\n",
    "- **`sensorViewGapSec`**: Time gap between displaying each camera view in the rotation, required if `displaySensorViews` is `true`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85728572",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96676590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Copyright (c) 2009-2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.**\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from mdx.mtmc.config import VizRtlsConfig\n",
    "from mdx.mtmc.utils.io_utils import load_json_from_file\n",
    "from mdx.mtmc.utils.viz_rtls_utils import VizConfig, GlobalObjects, read_rtls_log, \\\n",
    "  read_protobuf_data_with_amr_data, read_videos, plot_combined_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed15ab71",
   "metadata": {},
   "source": [
    "## Load config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51821e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz_config_path = \"resources/viz_rtls_config.json\"\n",
    "assert os.path.exists(viz_config_path), \"Viz config not found\"\n",
    "viz_config = VizRtlsConfig(**load_json_from_file(viz_config_path))\n",
    "viz_config = VizConfig(viz_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e76a2",
   "metadata": {},
   "source": [
    "## Load input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78437b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_map = cv2.imread(viz_config.rtls_config.input.mapPath)\n",
    "rtls_log, frame_ids = read_rtls_log(viz_config.rtls_config.input.rtlsLogPath)\n",
    "map_video_name_to_capture = None\n",
    "content_by_frame_id = None\n",
    "data_dict = dict()\n",
    "data_dict, amr_log, amr_frame_ids = read_protobuf_data_with_amr_data(viz_config.rtls_config.input.rawDataPath)\n",
    "if viz_config.rtls_config.output.displaySensorViews:\n",
    "    map_video_name_to_capture = read_videos(viz_config.rtls_config.input.videoDirPath)\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "video = cv2.VideoWriter(viz_config.rtls_config.output.outputVideoPath, fourcc, viz_config.fps,\n",
    "                        viz_config.output_video_size)\n",
    "global_people = GlobalObjects(viz_config)\n",
    "global_amrs = GlobalObjects(viz_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea1a75",
   "metadata": {},
   "source": [
    "## Create output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7428d25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "if viz_config.rtls_config.output.displaySensorViews:\n",
    "    if viz_config.sensor_views_layout == \"radial\":\n",
    "        print(\"Creating RTLS visualization with sensor views surrounding the map...\")\n",
    "    if viz_config.sensor_views_layout == \"split\":\n",
    "        print(\"Creating RTLS visualization with sensor views on the left...\")\n",
    "else:\n",
    "    print(\"Creating RTLS visualization without sensor views...\")\n",
    "    \n",
    "num_frames_to_skip = int(viz_config.rtls_config.output.skippedBeginningTimeSec * viz_config.fps)\n",
    "num_output_frames = int(viz_config.rtls_config.output.outputVideoDurationSec * viz_config.fps)\n",
    "num_total_frames = num_frames_to_skip + num_output_frames\n",
    "for frame_id in range(num_total_frames):\n",
    "    image_output = plot_combined_image(viz_config, image_map, map_video_name_to_capture, global_people, global_amrs,\n",
    "                                       data_dict, rtls_log, frame_ids, amr_log, amr_frame_ids, frame_id)\n",
    "\n",
    "    if frame_id > num_frames_to_skip:  \n",
    "        if viz_config.output_video_size[0] != image_output.shape[1]:\n",
    "            print(f\"ERROR: The frame width {image_output.shape[1]} is different from \"\n",
    "                  f\"output video width {viz_config.output_video_size[0]}.\"\n",
    "                  f\"The assumption is that all videos share the same size.\")\n",
    "            exit(1)\n",
    "        if viz_config.output_video_size[1] != image_output.shape[0]:\n",
    "            print(f\"ERROR: The frame height {image_output.shape[0]} is different from \"\n",
    "                  f\"output video height {viz_config.output_video_size[1]}.\"\n",
    "                  f\"The assumption is that all videos share the same size.\")\n",
    "            exit(1)\n",
    "        video.write(image_output)\n",
    "\n",
    "    processed_percentage = (frame_id / num_total_frames) * 100\n",
    "    if processed_percentage % 5 == 0:\n",
    "        end_time = time.time()\n",
    "        print(\"Time used: {0:.2f} sec. Finished {1:.1f}%.\".format(end_time - start_time, processed_percentage))\n",
    "\n",
    "video.release() \n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd0393",
   "metadata": {},
   "source": [
    "## [Optional] Re-encode video and play in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d790fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional] Re-encode video to reduce the file size\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# Check if FFmpeg is already installed\n",
    "if shutil.which(\"ffmpeg\") is None:\n",
    "    # Install FFmpeg using apt\n",
    "    subprocess.run([\"apt-get\", \"update\"])\n",
    "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"ffmpeg\"])\n",
    "else:\n",
    "    print(\"FFmpeg is already installed.\")\n",
    "\n",
    "output_video_path = viz_config.rtls_config.output.outputVideoPath.split(\".mp4\")[0] + \"_reencoded.mp4\"\n",
    "ffmpeg_command = \"ffmpeg -y -i {} -vcodec libx265 -crf 28 {}\".format(viz_config.rtls_config.output.outputVideoPath, output_video_path)\n",
    "os.system(ffmpeg_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cfb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Video\n",
    "Video.from_file(output_video_path, width=480)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
