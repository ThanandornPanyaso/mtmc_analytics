{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66322fd5-cba2-4887-880d-8b81ad68f8c6",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366da37-7489-4b6b-939b-27ef4237fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from collections import OrderedDict, deque \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from mdx.mtmc.core.calibration import Calibrator\n",
    "from mdx.mtmc.core.data import Loader, Preprocessor\n",
    "from mdx.mtmc.config import AppConfig\n",
    "from mdx.mtmc.utils.io_utils import load_json_from_file\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(message)s\", datefmt=\"%y/%m/%d %H:%M:%S\", level=logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b714b76-dce5-42d5-836f-dbb1999d7a0e",
   "metadata": {},
   "source": [
    "## Load config and configure param ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe30517-f7ce-4d7e-9bdf-ffef900a66d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_id = \"Building_K_Cam1\"\n",
    "confidence_range = (0.4, 0.5)\n",
    "bbox_area_range = (2000, 50000)\n",
    "bbox_aspect_ratio_range = (0., 2.)\n",
    "behavior_length_range = (0., 60.)\n",
    "inspect_behavior_level = False\n",
    "num_inspection_instances = 5\n",
    "\n",
    "app_config_path = \"resources/app_mtmc_config.json\"\n",
    "assert os.path.exists(app_config_path), \"App config not found\"\n",
    "app_config = AppConfig(**load_json_from_file(app_config_path))\n",
    "app_config.io.selectedSensorIds = [sensor_id]\n",
    "# Disable embedding-level and behavior-level filters to include all objects\n",
    "app_config.preprocessing.embeddingConfidenceThresh = 0.\n",
    "app_config.preprocessing.embeddingBboxAreaThresh = 0.\n",
    "app_config.preprocessing.embeddingBboxAspectRatioThresh = float(\"inf\")\n",
    "app_config.preprocessing.behaviorConfidenceThresh = 0.\n",
    "app_config.preprocessing.behaviorBboxAreaThresh = 0.\n",
    "app_config.preprocessing.behaviorBboxAspectRatioThresh = float(\"inf\")\n",
    "app_config.preprocessing.behaviorLengthThreshSec = 0.\n",
    "\n",
    "if inspect_behavior_level:\n",
    "    calibration_path = \"resources/calibration_building_k.json\"\n",
    "    assert os.path.exists(calibration_path), \"Calibration info not found\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e81deb1",
   "metadata": {},
   "source": [
    "## Load raw data and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data from the perception pipeline\n",
    "loader = Loader(app_config)\n",
    "frames = None\n",
    "json_data_path = app_config.io.jsonDataPath\n",
    "protobuf_data_path = app_config.io.protobufDataPath\n",
    "if os.path.isfile(json_data_path):\n",
    "    frames = loader.load_json_data_to_frames(json_data_path)\n",
    "elif os.path.isfile(protobuf_data_path):\n",
    "    frames = loader.load_protobuf_data_to_frames(protobuf_data_path)\n",
    "else:\n",
    "    logging.error(f\"ERROR: The JSON data path {json_data_path} and \"\n",
    "                  f\"protobuf data path {protobuf_data_path} do NOT exist.\")\n",
    "    exit(1)\n",
    "\n",
    "if inspect_behavior_level:\n",
    "    # Calibrate sensors\n",
    "    calibrator = Calibrator(app_config)\n",
    "    sensor_state_objects = calibrator.calibrate(calibration_path)\n",
    "\n",
    "    # Preprocess frames into behaviors and filter outliers\n",
    "    preprocessor = Preprocessor(app_config)\n",
    "    preprocessor.set_sensor_state_objects(sensor_state_objects)\n",
    "    behaviors = preprocessor.preprocess(frames)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f93c2e5c-7d0f-4274-b76b-bd143de2c99c",
   "metadata": {},
   "source": [
    "## Parse frames for embedding-level inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7135ad96-ff9f-4497-8b0c-0e4bf19d9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dict = OrderedDict()\n",
    "\n",
    "for frame in frames:\n",
    "    if frame.sensorId == sensor_id:\n",
    "        objects = frame.objects\n",
    "        for object_instance in objects:\n",
    "            confidence = object_instance.confidence\n",
    "            bbox = object_instance.bbox\n",
    "            bbox_width = bbox.rightX - bbox.leftX + 1.\n",
    "            bbox_height = bbox.bottomY - bbox.topY + 1.\n",
    "            bbox_area = bbox_width * bbox_height\n",
    "            bbox_aspect_ratio = bbox_width / bbox_height\n",
    "\n",
    "            # Exclude objects outside the given param ranges\n",
    "            if confidence < confidence_range[0]:\n",
    "                continue\n",
    "            if confidence > confidence_range[1]:\n",
    "                continue\n",
    "            if bbox_area < bbox_area_range[0]:\n",
    "                continue\n",
    "            if bbox_area > bbox_area_range[1]:\n",
    "                continue\n",
    "            if bbox_aspect_ratio < bbox_aspect_ratio_range[0]:\n",
    "                continue\n",
    "            if bbox_aspect_ratio > bbox_aspect_ratio_range[1]:\n",
    "                continue\n",
    "\n",
    "            object_key = frame.id + \" #-# \" + object_instance.id\n",
    "            frames_dict[object_key] = dict()\n",
    "            frames_dict[object_key][\"confidence\"] = confidence\n",
    "            frames_dict[object_key][\"bbox\"] = bbox\n",
    "\n",
    "print(list(frames_dict.items())[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "004c6412-0f9f-4132-86cc-6012c0e2487d",
   "metadata": {},
   "source": [
    "## Parse behaviors for behavior-level inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed1212-6a6c-4f09-9557-b405ae3a9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inspect_behavior_level:\n",
    "    behaviors_dict: Dict[str, Dict[str, Any]] = OrderedDict()\n",
    "    \n",
    "    for behavior in behaviors:\n",
    "        if behavior.sensorId == sensor_id:\n",
    "            object_id = behavior.objectId\n",
    "            start_frame = behavior.startFrame\n",
    "            end_frame = behavior.endFrame\n",
    "\n",
    "            # Aggregate confidences\n",
    "            confidences: List[float] = list()\n",
    "            for frame_id in range(int(start_frame), int(end_frame) + 1):\n",
    "                object_key = str(frame_id) + \" #-# \" + object_id\n",
    "                if object_key in frames_dict.keys():\n",
    "                    confidence = frames_dict[object_key][\"confidence\"]\n",
    "                else:\n",
    "                    confidence = 0.0\n",
    "                if confidence > 0:\n",
    "                    confidences.append(confidence)\n",
    "            if len(confidences) == 0:\n",
    "                continue\n",
    "            behavior_confidence = np.mean(confidences)\n",
    "            \n",
    "            # Aggregate bbox areas and aspect ratios\n",
    "            bbox_areas: List[float] = list()\n",
    "            bbox_aspect_ratios: List[float] = list()\n",
    "            for bbox in behavior.bboxes:\n",
    "                bbox_width = bbox.rightX - bbox.leftX + 1.\n",
    "                bbox_height = bbox.bottomY - bbox.topY + 1.\n",
    "                bbox_areas.append(bbox_width * bbox_height)\n",
    "                bbox_aspect_ratios.append(bbox_width / bbox_height)\n",
    "            if (len(bbox_areas) == 0) or (bbox_aspect_ratios == 0):\n",
    "                continue\n",
    "            behavior_bbox_area = np.mean(bbox_areas)\n",
    "            behavior_bbox_aspect_ratio = np.mean(bbox_aspect_ratios)\n",
    "            behavior_length = (behavior.end - behavior.timestamp).total_seconds()\n",
    "\n",
    "            # Exclude objects outside the given param ranges\n",
    "            if behavior_confidence < confidence_range[0]:\n",
    "                continue\n",
    "            if behavior_confidence > confidence_range[1]:\n",
    "                continue\n",
    "            if behavior_bbox_area < bbox_area_range[0]:\n",
    "                continue\n",
    "            if behavior_bbox_area > bbox_area_range[1]:\n",
    "                continue\n",
    "            if behavior_bbox_aspect_ratio < bbox_aspect_ratio_range[0]:\n",
    "                continue\n",
    "            if behavior_bbox_aspect_ratio > bbox_aspect_ratio_range[1]:\n",
    "                continue\n",
    "            if behavior_length < behavior_length_range[0]:\n",
    "                continue\n",
    "            if behavior_length > behavior_length_range[1]:\n",
    "                continue\n",
    "\n",
    "            for frame_id in range(int(start_frame), int(end_frame) + 1):\n",
    "                object_key = str(frame_id) + \" #-# \" + object_id\n",
    "                if object_key in frames_dict.keys():\n",
    "                    behaviors_dict[object_key] = frames_dict[object_key].copy()\n",
    "                    behaviors_dict[object_key][\"behavior_confidence\"] = behavior_confidence\n",
    "                    behaviors_dict[object_key][\"behavior_bbox_area\"] = behavior_bbox_area\n",
    "                    behaviors_dict[object_key][\"behavior_bbox_aspect_ratio\"] = behavior_bbox_aspect_ratio\n",
    "                    behaviors_dict[object_key][\"behavior_length\"] = behavior_length\n",
    "\n",
    "    print(list(behaviors_dict.items())[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bcb6626-f60b-4dc9-9871-cee9c3a889ab",
   "metadata": {},
   "source": [
    "## Show random instances for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9665d2c-3c80-467a-a6bf-771358552e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot on image frame and print anomaly information\n",
    "def display_anomaly_info(objects_dict: Dict[Tuple[str, str], Dict[str, Any]], object_key: str,\n",
    "                         video: cv2.VideoCapture, bbox_color: Tuple[int, int, int] = (255, 0, 0)) -> None:\n",
    "    \"\"\"\n",
    "    Displays anomaly information\n",
    "\n",
    "    :param Dict[Tuple[str, str], Dict[str, Any]] objects_dict: dictionary of objects\n",
    "    :param str object_key: key for the object\n",
    "    :param cv2.VideoCapture video: positive array\n",
    "    :param Tuple[int, int, int] bbox_color: bbox color\n",
    "    :return: None\n",
    "    ::\n",
    "\n",
    "        display_anomaly_info(objects_dict, object_key, video, bbox_color)\n",
    "    \"\"\"\n",
    "    object_tokens = object_key.split(\" #-# \")\n",
    "    frame_id = object_tokens[0]\n",
    "    object_id = object_tokens[1]\n",
    "    confidence = objects_dict[object_key][\"confidence\"]\n",
    "    bbox = objects_dict[object_key][\"bbox\"]\n",
    "\n",
    "    behavior_confidence = objects_dict[object_key].get(\"behavior_confidence\", None)\n",
    "    if behavior_confidence is not None:\n",
    "        behavior_confidence = round(behavior_confidence, 2)\n",
    "    behavior_bbox_area = objects_dict[object_key].get(\"behavior_bbox_area\", None)\n",
    "    if behavior_bbox_area is not None:\n",
    "        behavior_bbox_area = round(behavior_bbox_area, 2)\n",
    "    behavior_bbox_aspect_ratio = objects_dict[object_key].get(\"behavior_bbox_aspect_ratio\", None)\n",
    "    if behavior_bbox_aspect_ratio is not None:\n",
    "        behavior_bbox_aspect_ratio = round(behavior_bbox_aspect_ratio, 2)\n",
    "    behavior_length = objects_dict[object_key].get(\"behavior_length\", None)\n",
    "    if behavior_length is not None:\n",
    "        behavior_length = round(behavior_length, 2)\n",
    "\n",
    "    bbox_left_x = round(bbox.leftX, 2)\n",
    "    bbox_top_y = round(bbox.topY, 2)\n",
    "    bbox_right_x = round(bbox.rightX, 2)\n",
    "    bbox_bottom_y = round(bbox.bottomY, 2)\n",
    "    bbox_width = round(bbox_right_x - bbox_left_x, 2)\n",
    "    bbox_height = round(bbox_bottom_y - bbox_top_y, 2)\n",
    "    bbox_area = round(bbox_width * bbox_height, 2)\n",
    "    bbox_aspect_ratio = round(bbox_width / bbox_height, 2)\n",
    "\n",
    "    frame_id = int(frame_id)\n",
    "    success = video.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "    while not success:\n",
    "        success = video.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "\n",
    "    success, image_frame = video.read()\n",
    "    if success:\n",
    "        image_frame = cv2.cvtColor(image_frame, cv2.COLOR_BGR2RGB)\n",
    "        image_frame = cv2.putText(image_frame, sensor_id + \": %06d\" % frame_id, (10, 30),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        image_frame = cv2.rectangle(image_frame, (int(bbox_left_x), int(bbox_top_y)), \n",
    "                                    (int(bbox_right_x), int(bbox_bottom_y)), bbox_color, 2)\n",
    "        image_frame = cv2.putText(image_frame, object_id,\n",
    "                                    (int(bbox_left_x), int(bbox_top_y) - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, bbox_color, 2, cv2.LINE_AA)\n",
    "\n",
    "        plt.figure(figsize=(17, 13))\n",
    "        plt.imshow(image_frame)\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Frame ID: {frame_id}\")\n",
    "        print(f\"Object ID: {object_id}\")\n",
    "        print(f\"Confidence: {confidence}\")\n",
    "        print(f\"Bbox left X: {bbox_left_x}\")\n",
    "        print(f\"Bbox top Y: {bbox_top_y}\")\n",
    "        print(f\"Bbox right X: {bbox_right_x}\")\n",
    "        print(f\"Bbox bottom Y: {bbox_bottom_y}\")\n",
    "        print(f\"Bbox width: {bbox_width}\")\n",
    "        print(f\"Bbox height: {bbox_height}\")\n",
    "        print(f\"Bbox area: {bbox_area}\")\n",
    "        print(f\"Bbox aspect ratio: {bbox_aspect_ratio}\")\n",
    "        if behavior_confidence is not None:\n",
    "            print(f\"Behavior confidence: {behavior_confidence}\")\n",
    "        if behavior_bbox_area is not None:\n",
    "            print(f\"Behavior bbox area: {behavior_bbox_area}\")\n",
    "        if behavior_bbox_aspect_ratio is not None:\n",
    "            print(f\"Behavior bbox aspect ratio: {behavior_bbox_aspect_ratio}\")\n",
    "        if behavior_length is not None:\n",
    "            print(f\"Behavior length: {behavior_length}\")\n",
    "\n",
    "\n",
    "video_path = os.path.join(app_config.io.videoDirPath, sensor_id + \".mp4\")\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Embedding-level inspection\n",
    "if not inspect_behavior_level:\n",
    "    if len(frames_dict) == 0:\n",
    "        print(\"There is no anomaly found.\")\n",
    "        exit(0)\n",
    "    random_keys = random.sample(list(frames_dict), num_inspection_instances)\n",
    "\n",
    "    for object_key in frames_dict:\n",
    "        if object_key not in random_keys:\n",
    "            continue\n",
    "\n",
    "        display_anomaly_info(frames_dict, object_key, video)\n",
    "\n",
    "# Behavior-level inspection  \n",
    "else:\n",
    "    if len(behaviors_dict) == 0:\n",
    "        print(\"There is no anomaly found.\")\n",
    "        exit(0)\n",
    "    random_key = random.choice(list(behaviors_dict.keys()))\n",
    "    random_keys = deque([random_key])\n",
    "    num_attempts = 100\n",
    "\n",
    "    # Expand the behaviors based on consecutive frames\n",
    "    while len(random_keys) < num_inspection_instances and num_attempts > 0:\n",
    "        num_attempts -= 1\n",
    "        random_tokens = random_keys[0].split(\" #-# \")\n",
    "        left_frame_id = random_tokens[0]\n",
    "        object_id = random_tokens[1]\n",
    "        last_frame_id = str(int(left_frame_id) - 1)\n",
    "        for object_key in behaviors_dict.keys():\n",
    "            object_tokens = object_key.split(\" #-# \")\n",
    "            if (last_frame_id == object_tokens[0]) and (object_id == object_tokens[1]):\n",
    "                random_keys.appendleft(object_key)\n",
    "                break\n",
    "\n",
    "        right_frame_id = random_keys[-1].split(\" #-# \")[0]\n",
    "        next_frame_id = str(int(right_frame_id) + 1)\n",
    "        for object_key in behaviors_dict.keys():\n",
    "            object_tokens = object_key.split(\" #-# \")\n",
    "            if (next_frame_id == object_tokens[0]) and (object_id == object_tokens[1]):\n",
    "                random_keys.append(object_key)\n",
    "                break\n",
    "\n",
    "    for object_key in behaviors_dict:\n",
    "        if object_key not in random_keys:\n",
    "            continue\n",
    "\n",
    "        display_anomaly_info(behaviors_dict, object_key, video)\n",
    "\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "706d984c9c6beac43a7cfd9240131b30df33fac60be17d555c46d6e5ebc817d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
