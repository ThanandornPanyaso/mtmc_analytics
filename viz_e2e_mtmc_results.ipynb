{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from ipywidgets import Video\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "\n",
    "from mdx.mtmc.core.calibration import Calibrator\n",
    "from mdx.mtmc.core.data import Loader, Preprocessor\n",
    "from mdx.mtmc.core.clustering import Clusterer\n",
    "from mdx.mtmc.viz.mtmc_objects_in_grid import VizMTMCObjectsInGrid\n",
    "from mdx.mtmc.config import AppConfig, VizMtmcConfig\n",
    "from mdx.mtmc.utils.io_utils import load_json_from_file, make_clean_dir\n",
    "from mdx.mtmc.utils.viz_mtmc_utils import hash_frames, hash_behaviors, hash_mtmc_objects\n",
    "    \n",
    "logging.basicConfig(format=\"%(asctime)s - %(message)s\", datefmt=\"%y/%m/%d %H:%M:%S\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load configs and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_config_path = \"resources/app_mtmc_config.json\"\n",
    "assert os.path.exists(app_config_path), \"App config not found\"\n",
    "app_config = AppConfig(**load_json_from_file(app_config_path))\n",
    "app_config.io.enableDebug = True\n",
    "\n",
    "viz_config_path = \"resources/viz_mtmc_config.json\"\n",
    "assert os.path.exists(viz_config_path), \"Viz config not found\"\n",
    "viz_config = VizMtmcConfig(**load_json_from_file(viz_config_path))\n",
    "viz_config.setup.vizMtmcObjectsMode = \"grid\"\n",
    "viz_config.setup.enableMultiprocessing = True\n",
    "viz_config.setup.ffmpegRequired = True\n",
    "viz_config.io.selectedGlobalIds = [\"1\"]\n",
    "viz_config.io.outputDirPath = \"results\"\n",
    "viz_config.plotting.gridLayout = [3, 3]\n",
    "viz_config.plotting.outputFrameHeight = 1080\n",
    "\n",
    "calibration_path = \"resources/calibration_building_k.json\"\n",
    "assert os.path.exists(calibration_path), \"Calibration info not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data and process by batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/21 17:58:25 - Calibrating sensor Building_K_Cam1...\n",
      "25/01/21 17:58:25 - Calibrating sensor Building_K_Cam2...\n",
      "25/01/21 17:58:25 - Calibrating sensor Building_K_Cam3...\n",
      "25/01/21 17:58:25 - Calibrating sensor Building_K_Cam4...\n",
      "25/01/21 17:58:25 - Calibrating sensor Building_K_Cam5...\n",
      "25/01/21 17:58:25 - Calibrating sensor Building_K_Cam6...\n",
      "25/01/21 17:58:25 - Calibrating sensor Building_K_Cam7...\n",
      "25/01/21 17:58:25 - No. calibrated sensors: 7\n",
      "25/01/21 17:58:25 - Loading JSON data from metropolis-apps-data/playback/mtmc_buildingK_playback.json...\n",
      "25/01/21 17:58:51 - No. frames: 86476\n",
      "25/01/21 17:58:51 - No. objects: 310085\n",
      "25/01/21 17:58:58 - Filtering behaviors...\n",
      "25/01/21 17:58:58 - No. behaviors filtered by confidence: 149\n",
      "25/01/21 17:58:58 - No. behaviors filtered by bbox: 45\n",
      "25/01/21 17:58:58 - No. behaviors filtered by behavior length: 0\n",
      "25/01/21 17:58:58 - No. behaviors with empty embedding: 18\n",
      "25/01/21 17:58:58 - No. behaviors after filtering: 413\n",
      "25/01/21 17:58:58 - Finding co-existing behaviors...\n",
      "25/01/21 17:58:58 - No. co-existing behavior groups: 258\n",
      "25/01/21 17:58:58 - Clustering embeddings...\n",
      "25/01/21 17:58:58 - No. clusters: 17\n",
      "25/01/21 17:58:58 - Iteration #0 for re-assignment...\n",
      "25/01/21 17:58:58 - Grouping clusters...\n",
      "25/01/21 17:58:58 - Computing appearance distances...\n",
      "25/01/21 17:58:58 - Re-assigning co-existing behaviors to clusters...\n",
      "25/01/21 17:59:01 - Iteration #1 for re-assignment...\n",
      "25/01/21 17:59:01 - Grouping clusters...\n",
      "25/01/21 17:59:01 - Computing appearance distances...\n",
      "25/01/21 17:59:01 - Re-assigning co-existing behaviors to clusters...\n",
      "25/01/21 17:59:04 - Iteration #2 for re-assignment...\n",
      "25/01/21 17:59:04 - Grouping clusters...\n",
      "25/01/21 17:59:04 - Computing appearance distances...\n",
      "25/01/21 17:59:04 - Re-assigning co-existing behaviors to clusters...\n",
      "25/01/21 17:59:07 - Iteration #3 for re-assignment...\n",
      "25/01/21 17:59:07 - Grouping clusters...\n",
      "25/01/21 17:59:07 - Computing appearance distances...\n",
      "25/01/21 17:59:07 - Re-assigning co-existing behaviors to clusters...\n",
      "25/01/21 17:59:10 - Creating MTMC objects...\n"
     ]
    }
   ],
   "source": [
    "# Calibrate sensors\n",
    "calibrator = Calibrator(app_config)\n",
    "sensor_state_objects = calibrator.calibrate(calibration_path)\n",
    "\n",
    "# Load JSON data from the perception pipeline\n",
    "loader = Loader(app_config)\n",
    "frames = None\n",
    "json_data_path = app_config.io.jsonDataPath\n",
    "protobuf_data_path = app_config.io.protobufDataPath\n",
    "if os.path.isfile(json_data_path):\n",
    "    frames = loader.load_json_data_to_frames(json_data_path)\n",
    "elif os.path.isfile(protobuf_data_path):\n",
    "    frames = loader.load_protobuf_data_to_frames(protobuf_data_path)\n",
    "else:\n",
    "    logging.error(f\"ERROR: The JSON data path {json_data_path} and \"\n",
    "                  f\"protobuf data path {protobuf_data_path} do NOT exist.\")\n",
    "    exit(1)\n",
    "\n",
    "# Preprocess frames into behaviors and filter outliers\n",
    "preprocessor = Preprocessor(app_config)\n",
    "preprocessor.set_sensor_state_objects(sensor_state_objects)\n",
    "behaviors = preprocessor.preprocess(frames)\n",
    "\n",
    "# Cluster behaviors to get MTMC objects\n",
    "clusterer = Clusterer(app_config)\n",
    "mtmc_objects, _, _ = clusterer.cluster(behaviors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash lists to lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = hash_frames(frames, viz_config.io.selectedSensorIds)\n",
    "behaviors = hash_behaviors(behaviors, viz_config.io.selectedSensorIds,\n",
    "                           viz_config.io.selectedBehaviorIds)\n",
    "mtmc_objects = hash_mtmc_objects(mtmc_objects, viz_config.io.selectedGlobalIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize MTMC objects in grid mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_mtmc_objects_in_grid = VizMTMCObjectsInGrid(viz_config)\n",
    "output_video_dir = os.path.join(viz_config.io.outputDirPath, f\"viz_{viz_config.setup.vizMode}_in_{viz_config.setup.vizMtmcObjectsMode}\")\n",
    "make_clean_dir(output_video_dir)\n",
    "if not viz_config.setup.enableMultiprocessing:\n",
    "    for global_id in mtmc_objects.keys():\n",
    "        viz_mtmc_objects_in_grid.plot(global_id, output_video_dir, frames, behaviors, mtmc_objects)\n",
    "else:\n",
    "    with Pool() as pool:\n",
    "        pool.starmap(viz_mtmc_objects_in_grid.plot,\n",
    "                    zip(list(mtmc_objects), repeat(output_video_dir), repeat(frames),\n",
    "                        repeat(behaviors), repeat(mtmc_objects)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/viz_mtmc_objects_in_grid/object_id_1.mp4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_video_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_id_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mviz_config\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mselectedGlobalIds[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mVideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m480\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mtmc_analytics/lib/python3.10/site-packages/ipywidgets/widgets/widget_media.py:192\u001b[0m, in \u001b[0;36mVideo.from_file\u001b[0;34m(cls, filename, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_file\u001b[39m(\u001b[38;5;28mcls\u001b[39m, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvideo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mtmc_analytics/lib/python3.10/site-packages/ipywidgets/widgets/widget_media.py:43\u001b[0m, in \u001b[0;36m_Media._from_file\u001b[0;34m(cls, tag, filename, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_file\u001b[39m(\u001b[38;5;28mcls\u001b[39m, tag, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Create an :class:`Media` from a local file.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    Returns an `Media` with the value set from the filename.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_file_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_guess_format(tag, filename)\n",
      "File \u001b[0;32m~/miniconda3/envs/mtmc_analytics/lib/python3.10/site-packages/ipywidgets/widgets/widget_media.py:94\u001b[0m, in \u001b[0;36m_Media._load_file_value\u001b[0;34m(cls, filename)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/viz_mtmc_objects_in_grid/object_id_1.mp4'"
     ]
    }
   ],
   "source": [
    "output_video_path = os.path.join(output_video_dir, f\"object_id_{viz_config.io.selectedGlobalIds[0]}.mp4\")\n",
    "Video.from_file(output_video_path, width=480)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtmc_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
